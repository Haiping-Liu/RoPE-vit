{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rope_vit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/miniconda3/envs/rope_vit/lib/python3.9/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/opt/miniconda3/envs/rope_vit/lib/python3.9/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:259: UserWarning: Overwriting rope_axial_deit_small_patch16_LS in registry with models.vit_rope.rope_axial_deit_small_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_axial_deit_small_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:273: UserWarning: Overwriting rope_axial_deit_base_patch16_LS in registry with models.vit_rope.rope_axial_deit_base_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_axial_deit_base_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:286: UserWarning: Overwriting rope_axial_deit_large_patch16_LS in registry with models.vit_rope.rope_axial_deit_large_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_axial_deit_large_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:300: UserWarning: Overwriting rope_mixed_deit_small_patch16_LS in registry with models.vit_rope.rope_mixed_deit_small_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_mixed_deit_small_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:314: UserWarning: Overwriting rope_mixed_deit_base_patch16_LS in registry with models.vit_rope.rope_mixed_deit_base_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_mixed_deit_base_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:327: UserWarning: Overwriting rope_mixed_deit_large_patch16_LS in registry with models.vit_rope.rope_mixed_deit_large_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_mixed_deit_large_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:342: UserWarning: Overwriting rope_axial_ape_deit_small_patch16_LS in registry with models.vit_rope.rope_axial_ape_deit_small_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_axial_ape_deit_small_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:357: UserWarning: Overwriting rope_axial_ape_deit_base_patch16_LS in registry with models.vit_rope.rope_axial_ape_deit_base_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_axial_ape_deit_base_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:371: UserWarning: Overwriting rope_axial_ape_deit_large_patch16_LS in registry with models.vit_rope.rope_axial_ape_deit_large_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_axial_ape_deit_large_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:386: UserWarning: Overwriting rope_mixed_ape_deit_small_patch16_LS in registry with models.vit_rope.rope_mixed_ape_deit_small_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_mixed_ape_deit_small_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:401: UserWarning: Overwriting rope_mixed_ape_deit_base_patch16_LS in registry with models.vit_rope.rope_mixed_ape_deit_base_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_mixed_ape_deit_base_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n",
      "/Users/user/Desktop/rope-vit/rope-vit/models/vit_rope.py:415: UserWarning: Overwriting rope_mixed_ape_deit_large_patch16_LS in registry with models.vit_rope.rope_mixed_ape_deit_large_patch16_LS. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def rope_mixed_ape_deit_large_patch16_LS(pretrained=False, img_size=224,  **kwargs):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing key freqs_t_x from pretrained checkpoint\n",
      "Removing key freqs_t_y from pretrained checkpoint\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "rope_vit_models(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "    (norm): Identity()\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x RoPE_Layer_scale_init_Block(\n",
       "      (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): RoPEAttention(\n",
       "        (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "        (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "        (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (drop_path): Identity()\n",
       "      (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): Mlp(\n",
       "        (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "        (drop1): Dropout(p=0.0, inplace=False)\n",
       "        (norm): Identity()\n",
       "        (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "        (drop2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "  (head): Linear(in_features=384, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image, ImageDraw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from deit.models_v2_rope import compute_mixed_cis, init_t_xy\n",
    "from models import vit_rope\n",
    "\n",
    "mix_model = vit_rope.rope_mixed_deit_base_patch16_LS(pretrained=True)\n",
    "mix_model.eval()\n",
    "\n",
    "axial_model = vit_rope.rope_axial_deit_small_patch16_LS(pretrained=True)\n",
    "axial_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token | shape: torch.Size([1, 1, 768]) | requires_grad: True\n",
      "freqs | shape: torch.Size([2, 12, 384]) | requires_grad: True\n",
      "patch_embed.proj.weight | shape: torch.Size([768, 3, 16, 16]) | requires_grad: True\n",
      "patch_embed.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.0.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.0.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.0.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.0.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.0.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.0.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.0.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.1.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.1.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.1.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.1.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.1.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.1.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.1.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.2.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.2.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.2.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.2.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.2.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.2.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.2.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.3.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.3.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.3.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.3.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.3.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.3.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.3.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.4.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.4.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.4.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.4.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.4.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.4.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.4.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.5.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.5.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.5.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.5.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.5.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.5.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.5.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.6.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.6.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.6.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.6.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.6.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.6.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.6.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.7.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.7.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.7.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.7.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.7.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.7.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.7.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.8.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.8.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.8.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.8.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.8.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.8.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.8.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.9.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.9.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.9.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.9.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.9.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.9.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.9.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.10.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.10.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.10.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.10.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.10.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.10.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.10.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.gamma_1 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.gamma_2 | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.norm1.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.norm1.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.attn.qkv.weight | shape: torch.Size([2304, 768]) | requires_grad: True\n",
      "blocks.11.attn.qkv.bias | shape: torch.Size([2304]) | requires_grad: True\n",
      "blocks.11.attn.proj.weight | shape: torch.Size([768, 768]) | requires_grad: True\n",
      "blocks.11.attn.proj.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.norm2.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.norm2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "blocks.11.mlp.fc1.weight | shape: torch.Size([3072, 768]) | requires_grad: True\n",
      "blocks.11.mlp.fc1.bias | shape: torch.Size([3072]) | requires_grad: True\n",
      "blocks.11.mlp.fc2.weight | shape: torch.Size([768, 3072]) | requires_grad: True\n",
      "blocks.11.mlp.fc2.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "norm.weight | shape: torch.Size([768]) | requires_grad: True\n",
      "norm.bias | shape: torch.Size([768]) | requires_grad: True\n",
      "head.weight | shape: torch.Size([1000, 768]) | requires_grad: True\n",
      "head.bias | shape: torch.Size([1000]) | requires_grad: True\n"
     ]
    }
   ],
   "source": [
    "for name, param in mix_model.named_parameters():\n",
    "    print(f\"{name} | shape: {param.shape} | requires_grad: {param.requires_grad}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mixed_cis(freqs, t_x, t_y, num_heads):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        freqs: [2, num_heads, freq_dim]\n",
    "        t_x: [N]\n",
    "        t_y: [N]\n",
    "        num_heads: int\n",
    "    returns:\n",
    "        freqs_cis: [N, num_heads, freq_dim]\n",
    "    \"\"\"\n",
    "    with torch.cuda.amp.autocast(enabled=False):\n",
    "        # freqs: [2, num_heads, freq_dim]\n",
    "        freqs_x = torch.einsum(\"n,hf->nhf\", t_x, freqs[0])  # [N, H, F]\n",
    "        freqs_y = torch.einsum(\"n,hf->nhf\", t_y, freqs[1])  # [N, H, F]\n",
    "        angles = freqs_x + freqs_y\n",
    "        freqs_cis = torch.polar(torch.ones_like(angles), angles)  # [N, H, F]\n",
    "    return freqs_cis\n",
    "\n",
    "def compute_axial_cis(dim: int, end_x: int, end_y: int, theta: float = 100.0):\n",
    "    freqs_x = 1.0 / (theta ** (torch.arange(0, dim, 4)[: (dim // 4)].float() / dim))\n",
    "    freqs_y = 1.0 / (theta ** (torch.arange(0, dim, 4)[: (dim // 4)].float() / dim))\n",
    "\n",
    "    t_x, t_y = init_t_xy(end_x, end_y)\n",
    "    freqs_x = torch.outer(t_x, freqs_x)\n",
    "    freqs_y = torch.outer(t_y, freqs_y)\n",
    "    freqs_cis_x = torch.polar(torch.ones_like(freqs_x), freqs_x)\n",
    "    freqs_cis_y = torch.polar(torch.ones_like(freqs_y), freqs_y)\n",
    "    return torch.cat([freqs_cis_x, freqs_cis_y], dim=-1)\n",
    "\n",
    "\n",
    "def plot_tsne_subplot(freqs_cis, layer_idx, ax, N, width=14):\n",
    "    rotary_codes_complex = freqs_cis.reshape(N, -1)\n",
    "    rotary_codes = np.concatenate([\n",
    "        rotary_codes_complex.real.numpy(),\n",
    "        rotary_codes_complex.imag.numpy()\n",
    "    ], axis=-1).astype(np.float32)\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    tsne_result = tsne.fit_transform(rotary_codes)\n",
    "\n",
    "    dists = pairwise_distances(rotary_codes)\n",
    "    np.fill_diagonal(dists, np.inf)\n",
    "    i, j = np.unravel_index(np.argmin(dists), dists.shape)\n",
    "    min_dist = dists[i, j]\n",
    "\n",
    "    # 可视化\n",
    "    scatter = ax.scatter(tsne_result[:, 0], tsne_result[:, 1], c=np.arange(N), cmap='viridis', s=20)\n",
    "    ax.plot(\n",
    "        [tsne_result[i, 0], tsne_result[j, 0]],\n",
    "        [tsne_result[i, 1], tsne_result[j, 1]],\n",
    "        'r-', linewidth=1.5\n",
    "    )\n",
    "    ax.scatter(tsne_result[[i, j], 0], tsne_result[[i, j], 1], color='red', s=30)\n",
    "    ax.set_title(f'Layer {layer_idx} (min dist={min_dist:.2f})', fontsize=9)\n",
    "    ax.axis('off')\n",
    "\n",
    "def plot_tsne(freqs_cis, N, width=14):\n",
    "    rotary_codes_complex = freqs_cis.reshape(N, -1)\n",
    "    rotary_codes = np.concatenate([\n",
    "        rotary_codes_complex.real.numpy(),\n",
    "        rotary_codes_complex.imag.numpy()\n",
    "    ], axis=-1).astype(np.float32)\n",
    "\n",
    "    tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
    "    tsne_result = tsne.fit_transform(rotary_codes)\n",
    "\n",
    "    # 距离计算\n",
    "    dists = pairwise_distances(rotary_codes)\n",
    "    np.fill_diagonal(dists, np.inf)\n",
    "    i, j = np.unravel_index(np.argmin(dists), dists.shape)\n",
    "    min_dist = dists[i, j]\n",
    "\n",
    "    plt.scatter(tsne_result[:, 0], tsne_result[:, 1], c=np.arange(N), cmap='viridis', s=20)\n",
    "    plt.title(\"t-SNE of RoPE-Axial Encoding (Fixed)\")\n",
    "    plt.show()\n",
    "\n",
    "import seaborn as sns\n",
    "def plot_heatmap(freqs_cis, layer_idx=None, title_prefix=\"\"):\n",
    "    \"\"\"\n",
    "    args:\n",
    "        freqs_cis: [N, H, D] numpy array\n",
    "    \"\"\"\n",
    "    rotary_codes_complex = freqs_cis.reshape(N, -1)\n",
    "    rotary_codes = np.concatenate([\n",
    "        rotary_codes_complex.real.numpy(),\n",
    "        rotary_codes_complex.imag.numpy()\n",
    "    ], axis=-1).astype(np.float32)\n",
    "    dists = pairwise_distances(rotary_codes)\n",
    "    np.fill_diagonal(dists, np.nan)  \n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(dists, cmap='viridis', square=True, cbar=True)\n",
    "    plt.xlabel(\"Position Index\")\n",
    "    plt.ylabel(\"Position Index\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def analyze_mix_model(model, freqs, t_x, t_y, layers=list(range(12)), width=14):\n",
    "    num_heads = model.num_heads\n",
    "    embed_dim = model.embed_dim\n",
    "    freq_dim_per_head = embed_dim // num_heads // 2\n",
    "    N = len(t_x)\n",
    "\n",
    "    fig, axes = plt.subplots(4, 3, figsize=(12, 10))\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for idx, layer_idx in enumerate(layers):\n",
    "        freqs_layer = freqs[:, layer_idx].view(2, num_heads, freq_dim_per_head)\n",
    "        cis = compute_mixed_cis(freqs_layer, t_x, t_y, num_heads)\n",
    "        plot_tsne_subplot(cis, layer_idx, axes[idx], N, width)\n",
    "    plt.tight_layout()\n",
    "    plt.suptitle(\"RoPE Injectivity Check across Layers\", fontsize=14, y=1.02)\n",
    "    plt.subplots_adjust(top=0.92)\n",
    "    plt.show()\n",
    "\n",
    "def analyze_axial_model(model, end_x, end_y, width=14):\n",
    "    embed_dim = model.embed_dim\n",
    "    cis = compute_axial_cis(embed_dim, end_x, end_y)\n",
    "    N = end_x * end_y\n",
    "    plot_tsne(cis, N, width)\n",
    "    \n",
    "def idx_to_coord(idx, width=14):\n",
    "    return int(idx % width), int(idx // width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_x = end_y = 14 # 对应224x224 / 16 = 14x14 patch\n",
    "t_x, t_y = init_t_xy(end_x, end_y)\n",
    "N = end_x * end_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_axial_model(axial_model, end_x, end_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 384])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = mix_model.freqs.detach().cpu()\n",
    "freqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = mix_model.freqs.detach().cpu()\n",
    "plot_heatmap(freqs[:,0,:], layer_idx=0, title_prefix=\"RoPE-Mixed\")\n",
    "analyze_mix_model(mix_model, freqs, t_x, t_y, layers=np.arange(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27260, 128, 160, 3)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import os\n",
    "\n",
    "root_dir = './data/depth_data'\n",
    "with h5py.File(os.path.join(root_dir, \"depth_train.h5\"), \"r\") as f:\n",
    "    image = f[\"image\"]\n",
    "    depth = f[\"depth\"]\n",
    "    print(image.shape)\n",
    "    print(type(image[0]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rope_vit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
